# [Advanced WebCrawling] WEEK4

> ì‘ì„±ì: ì‹ ìœ¤ì§„

â€» ë³¸ êµì•ˆì€ ë…¸ì…˜(notion)ì—ì„œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ë³€í™˜í•˜ë©´ì„œ ë¹ ì§„ íŒŒì¼ë“¤ì´ ìˆìŠµë‹ˆë‹¤.

ì™„ì „í•œ ë‚´ìš©ì˜ êµì•ˆì€ ì•„ë˜ ë§í¬ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš” :)

- [ë…¸ì…˜ ë§í¬](https://www.notion.so/cosadama/Advanced-WebCrawling-WEEK4-47d1d67a39664ed6aa50a3e5bb76e10d)

![banner](./images/banner.png)

ì´ë²ˆ ì£¼ì°¨ì—ëŠ” í…ìŠ¤íŠ¸ ì—ë””í„°ë¥¼ ì„¤ì¹˜í•´ë³´ë ¤ê³  í•´ìš” ğŸ˜²

ì •ë“¤ì—ˆë˜ jupyter notebookì„ ë– ë‚˜ í”„ë¡œê·¸ë˜ë°ì— í•œ ë°œì§ ë” ë‹¤ê°€ê°€ë³´ëŠ” ê²ƒì´ì£ .

<br>

ì´ë¥¼ ê¸°ë…í•˜ì—¬ [Gë§ˆì¼“ ì‚¬ì´íŠ¸ì˜ ë² ìŠ¤íŠ¸ ì¹´í…Œê³ ë¦¬](http://corners.gmarket.co.kr/Bestsellers) í¬ë¡¤ë§ ì‹¤ìŠµ ê³¼ì œë„ ì¤€ë¹„í•´ ë´¤ìŠµë‹ˆë‹¤.

ì˜ˆìƒ ê³¼ì œ ìˆ˜í–‰ ì‹œê°„ì€ **6ì‹œê°„ ì´ìƒ**ì´ì—ìš”. ê·¸ë™ì•ˆ ê³µë¶€ë¥¼ ì„¤ë ì„¤ë í–ˆë‹¤ë©´ ìˆ˜í–‰ ì‹œê°„ì´ ë°°ê°€ ë˜ê² ì£ ? ğŸ˜–

**ì‹¤ìŠµ ê³¼ì œëŠ” ì§ˆì˜ì‘ë‹µì„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ì‹  ê³¼ì œ ê¸°í•œì„ í•œ ë‹¬ë¡œ ëŠ˜ë ¸ì–´ìš”.**

ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ì— ë¨¸ë¦¬ë¥¼ ì‹¸ë§¤ë©°, ìˆ˜ë§ì€ ë‚œê´€ì„ ì •ë³µí•´ê°€ëŠ” ì§œë¦¿í•¨ì„ ì•Œì•„ê°€ì‹œê¸¸ ë°”ëë‹ˆë‹¤ ğŸ¤©

<br>

##### ğŸ“¢ **ê³µì§€ì‚¬í•­**


---

ë³¸ êµì•ˆì—ì„œ Visual Studio Code(VS Code) ê´€ë ¨ ì˜ìƒì€ ìë°”ìŠ¤í¬ë¦½íŠ¸(JavaScript)ë¥¼ ì˜ˆì‹œë¡œ ì„¤ëª…ë©ë‹ˆë‹¤.

ì™œ íŒŒì´ì¬ì´ ì•„ë‹Œì§€ ê¶ê¸ˆí•˜ì‹¤ í…ë°ìš”. í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë§Œ ë‹¤ë¥¼ ë¿ VS Codeë¥¼ ì‚¬ìš©í•˜ëŠ” ë°ëŠ” í° ì°¨ì´ê°€ ì—†ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ê°•ì‚¬ë‹˜ì´ íŒŒì´ì¬ì„ ì˜ˆì‹œë¡œ ì„¤ëª…í•´ ì£¼ì‹œëŠ” ì˜ìƒë„ ìˆì§€ë§Œ, ìë°”ìŠ¤í¬ë¦½íŠ¸ ì˜ìƒì´ ì¢€ ë” ìµœê·¼ì— ì´¬ì˜ëê³  ìœ ìš©í•œ ê¸°ëŠ¥ë“¤ì„ ì¶”ê°€ë¡œ ì„¤ëª…í•´ ì£¼ì‹­ë‹ˆë‹¤.

í”„ë¡œê·¸ë˜ë° ì–¸ì–´ê°€ ë‹¤ë¥´ë‹¤ê³  ëŒ€ì¶© ë³´ì§€ ë§ˆì‹œê³  ê¼¼ê¼¼íˆ ì‹œì²­í•´ ì£¼ì„¸ìš” ğŸ˜š

<br>

<br>

## 1. ì‹¤ìŠµ í™˜ê²½ ì¤€ë¹„

2ì£¼ì°¨ì—ì„œ ì–¸ê¸‰í–ˆë˜ í…ìŠ¤íŠ¸ ì—ë””í„°ë¥¼ ì„¤ì¹˜í•´ ë³´ê² ìŠµë‹ˆë‹¤.

ê°„ë‹¨í•œ py íŒŒì¼ ìˆ˜ì •ì´ë¼ë©´ jupyter notebookë„ ê´œì°®ì§€ë§Œ, ê¸´ ì½”ë“œë¥¼ ì‘ì„±í•˜ê¸°ì—ëŠ” ì •~ë§ ë¶ˆí¸í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

ì €í¬ëŠ” í…ìŠ¤íŠ¸ ì—ë””í„° ì¤‘ ê°€ì¥ ì¸ê¸° ìˆëŠ” VS Codeë¥¼ ì‚¬ìš©í•  ì˜ˆì •ì´ì—ìš”.

ì•„ë˜ ì˜ìƒë“¤ì„ ë”°ë¼ ì‹ ì„¸ê³„ë¥¼ ì—¬í–‰í•´ë³´ì‹œê¸¸ ë°”ëë‹ˆë‹¤ ğŸ‘©â€ğŸš€

<br>

### 1-1. VS Code ì„¤ì¹˜í•˜ê¸°

---

**2ë¶„ 30ì´ˆë¶€í„° ì‹œì²­**í•´ì£¼ì„¸ìš”.

- í˜¼ê³µ ìë°”ìŠ¤í¬ë¦½íŠ¸ 1ê°• - 1.2ì ˆ ê°œë°œ í™˜ê²½ ì„¤ì¹˜: [https://youtu.be/pwR0y76Od_U?t=151](https://youtu.be/pwR0y76Od_U?t=151)

<br>

### 1-2. VS Code ì‚¬ìš© íŒ â­

---

- í˜¼ê³µ ìë°”ìŠ¤í¬ë¦½íŠ¸ 4ê°• - Visual Studio Code í™˜ê²½ ì„¤ì •í•˜ê¸°: [https://youtu.be/2qqJUx_S33M](https://youtu.be/2qqJUx_S33M)

<br>

### 1-3. VS Codeì—ì„œ ì‘ì—…í•˜ê¸°

---

ê¸°ë³¸ì ì¸ ì‚¬ìš©ë²•ì— ëŒ€í•œ ì˜ìƒë“¤ì…ë‹ˆë‹¤. ì§‘ì¤‘í•´ì„œ ë´ì£¼ì„¸ìš” ğŸ¿

- **ê¸°ë³¸ ì‚¬ìš©ë²•**
  
    [https://www.youtube.com/watch?v=K8qVH8V0VvY](https://www.youtube.com/watch?v=K8qVH8V0VvY)
    
- **(ë³´ì¶©) ì‘ì—… ì˜ì—­ ì‚¬ìš© ì˜ìƒ** -- ë…¸ì…˜ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš” :)

<br>

## 2. Scrapy Logging

Scrapyë¥¼ ì‹¤í–‰í–ˆì„ ë•Œ ì¶œë ¥ë˜ëŠ” ë¡œê·¸ëŠ” ì²˜ìŒì—ëŠ” ì‹ ê¸°í•˜ì§€ë§Œ, ì¥í™©í•œ íƒ“ì— ì˜¤ë¥˜ ë©”ì„¸ì§€ë¥¼ ì°¾ê¸° í˜ë“¤ê²Œ í•©ë‹ˆë‹¤.

- ìˆœê°„í¬ì°© ì˜¤ë¥˜ ë©”ì„¸ì§€ ì°¾ê¸° ğŸ”
    - ìˆ¨ì€ ì˜¤ë¥˜ ì°¾ê¸°.mp4 -- ë…¸ì…˜ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš” :)


<br>

ì´ëŸ¬í•œ ê³ ë¯¼ì€ **settings.py**ì— LOG_LEVEL ì„¤ì •ì„ ì¶”ê°€í•´ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

##### ğŸ’¡ **ê°œë…ì¡ê¸°: LOG_LEVEL ì„¤ì •**


---

LOG_LEVELì€ í‘œì‹œí•  ë©”ì„¸ì§€ì˜ ìˆ˜ì¤€ì„ ê²°ì •í•©ë‹ˆë‹¤. Scrapyì˜ í‘œì¤€ì ì¸ LOG_LEVELì€ ì´ 5ê°€ì§€ì…ë‹ˆë‹¤.

1. CRITICAL â€” ìµœê³  ì‹¬ê°ë„
2. ERROR â€” ì¶”ì²œ
3. WARNING
4. INFO
5. DEBUG â€” ìµœì € ì‹¬ê°ë„, ê¸°ë³¸ ì„¤ì •ê³¼ ë™ì¼

ë¡œê·¸ ìˆ˜ì¤€ì„ WARNINGìœ¼ë¡œ ì„¤ì •í•˜ë©´ CRITICAL, ERROR, WARNING ë¡œê·¸ë§Œ ì¶œë ¥ë˜ê³ , DEBUGë¡œ ì„¤ì •í•˜ë©´ ëª¨ë“  ë¡œê·¸ê°€ ì¶œë ¥ë©ë‹ˆë‹¤. ìˆ˜ì¤€ì„ ë³€ê²½í•˜ë©´ì„œ ì°¨ì´ë¥¼ íŒŒì•…í•´ë³´ì„¸ìš”.

##### ğŸ“– **ì°¸ê³ í•˜ê¸°: ë¡œê¹…(Logging)ì´ë€?**


---

ë¡œê¹…ì´ë€ ë¡œê·¸ë¥¼ ê¸°ë¡í•˜ëŠ” í–‰ìœ„ë¥¼ ë§í•©ë‹ˆë‹¤.

í”„ë¡œê·¸ë˜ë°ì—ì„œ ë¡œê·¸(Log)ëŠ” ìš´ì˜ì²´ì œë‚˜ ì†Œí”„íŠ¸ì›¨ì–´ê°€ ì‹¤í–‰í•˜ëŠ” ë„ì¤‘ ë°œìƒí•˜ëŠ” ì´ë²¤íŠ¸, í˜¹ì€ ê°ê¸° ë‹¤ë¥¸ ì‚¬ìš©ìì˜ í†µì‹  ì†Œí”„íŠ¸ì›¨ì–´ ê°„ì˜ ë©”ì„¸ì§€ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.

ì¶œì²˜: [[ìœ„í‚¤ë°±ê³¼] ë¡œê·¸íŒŒì¼](https://ko.wikipedia.org/wiki/%EB%A1%9C%EA%B7%B8%ED%8C%8C%EC%9D%BC)

<br>

```python
#settings.py
LOG_LEVEL = 'ERROR'    # ì§ì ‘ ì…ë ¥
```

![0](./images/WEEK4/0.png)

- í¸ì•ˆí•´ì§„ ì˜¤ë¥˜ ì°¾ê¸°.mp4 -- ë…¸ì…˜ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš” :)

ì˜¤ë¥˜ ë©”ì„¸ì§€ë¥¼ ì°¾ê¸° ë§¤ìš° ì‰¬ì›Œì¡Œë„¤ìš” ğŸ˜†

<br>

ì´ì™¸ì—ë„ ì¶œë ¥ë˜ëŠ” printë¬¸ì„ ë³´ê³  ì–´ëŠ ë¶€ë¶„ì´ ì˜ëª»ëëŠ”ì§€ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 3ì£¼ì°¨ì˜ **st11_best.py**ì— ì‘ì„±í–ˆë˜ printë¬¸ 3ê°œë¥¼ ê¸°ì–µí•˜ì‹œë‚˜ìš”?

- ê¸°ì–µì´ ë‚˜ì§€ ì•ŠëŠ”ë‹¤ë©´...
  
    ```python
    #st11_best.py: ìµœì¢…
    import scrapy
    from st11.items import St11Item
    
    class St11BestSpider(scrapy.Spider):
        name = 'st11_best'
    
        def start_requests(self):
            yield scrapy.Request(url="https://www.11st.co.kr/browsing/BestSeller.tmall?method=getBestSellerMain&cornerNo=0",
                                 callback=self.parse_mainpages)
            
        def parse_mainpages(self, response):
            print("parse_mainpages")
            category_names = response.css(quiz:ë©”ì¸ ì¹´í…Œê³ ë¦¬ëª…ì˜ css ì„ íƒì ê²½ë¡œ).getall()
            for idx, name in enumerate(category_names):
                yield scrapy.Request(url="https://www.11st.co.kr/browsing/BestSeller.tmall?method=getBestSellerMain&cornerNo="+str(idx), 
                                     callback=self.parse_items, 
                                     meta={'maincategory_name':category_names[idx], 'subcategory_name':'All'})
            for idx, name in enumerate(category_names):
                yield scrapy.Request(url="https://www.11st.co.kr/browsing/BestSeller.tmall?method=getBestSellerMain&cornerNo="+str(idx), 
                                     callback=self.parse_subcategory, 
                                     meta={'maincategory_name':category_names[idx],'index':idx}
                                    )
        
        def parse_subcategory(self, response):
            print('parse_subcategory', response.meta['maincategory_name'])        
            subcategory_names = response.css(quiz:ì„œë¸Œ ì¹´í…Œê³ ë¦¬ëª…ì˜ css ì„ íƒì ê²½ë¡œ).getall()
            subcategory_lists = response.css('div.sub_category_box li a::attr("onclick")').re('\(.*\)')
            subcategory_idcs = []
            for i in subcategory_lists:
                if i[2] == ',':
                    subcategory_idcs.append((int(i[1]),int(i[3:-1])))
                else:
                    subcategory_idcs.append((int(i[1:3]),int(i[4:-1])))
            
            for idx, sub in enumerate(subcategory_idcs):
                if sub[0] == response.meta['index']:
                    yield scrapy.Request(url="https://www.11st.co.kr/browsing/BestSeller.tmall?method=getBestSellerMain&cornerNo=" + str(sub[0]) + "&dispCtgrNo=" + str(sub[1]), 
                                         callback=self.parse_items,
                                         meta={'maincategory_name':response.meta['maincategory_name'], 
                                                                          'subcategory_name':subcategory_names[idx]}
                                        )
                else:
                    continue
    
        # ë©”ì¸ ì¹´í…Œê³ ë¦¬, ì„œë¸Œ ì¹´í…Œê³ ë¦¬ì˜ ì •ë³´ë¥¼ ëª¨ë‘ í¬ë¡¤ë§í•˜ëŠ” ë©”ì„œë“œ. ì½”ë“œëŠ” ì²˜ìŒê³¼ ë™ì¼
        def parse_items(self, response):
            print('parse_items', response.meta['maincategory_name'], response.meta['subcategory_name'])
            best_items = response.css('div.viewtype.catal_ty')
            for idx, item in enumerate(best_items[1].css('li')):
                doc = St11Item()
                
                ranking = idx + 1
                title = item.css(quiz:ë² ìŠ¤íŠ¸ ìƒí’ˆì´ë¦„ì˜ css ì„ íƒì ê²½ë¡œ).get().strip()
                ori_price = item.css(quiz:í• ì¸ì „ê°€ê²©ì˜ css ì„ íƒì ê²½ë¡œ).get()
                dis_price = item.css(quiz:í• ì¸ëœê°€ê²©ì˜ css ì„ íƒì ê²½ë¡œ).get()
                
                if ori_price == None:
                    ori_price = dis_price
                ori_price = ori_price.replace(',','').replace('ì›','')
                dis_price = dis_price.replace(',','').replace('ì›','')
                
                doc['main_category_name'] = response.meta['maincategory_name']
                doc['sub_category_name'] = response.meta['subcategory_name']
                doc['ranking'] = ranking
                doc['title'] = title
                doc['ori_price'] = ori_price
                doc['dis_price'] = dis_price
         
                yield doc
    ```
    

'parse_mainpages 'ì™€ 'parse_subcategory'ì€ ì¶œë ¥ë˜ëŠ”ë° 'parse_items'ê°€ ë³´ì´ì§€ ì•ŠëŠ”ë‹¤ë©´, **parse_items ë©”ì„œë“œ**ì— ë¬¸ì œê°€ ìˆë‹¤ê³  ì¶”ì¸¡í•  ìˆ˜ ìˆëŠ” ê²ƒì´ì£ . ë©”ì„œë“œì™€ ë°˜ë³µë¬¸ ì¤‘ê°„ì¤‘ê°„ printë¬¸ì„ ë„£ê³  ì‹¤í–‰í•´, ì½”ë“œë¥¼ ì˜ ì‘ì„±í•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤ ğŸ‘¨â€ğŸ”§

<br>

ë§Œì•½ ë¡œê·¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ì‹¶ë‹¤ë©´ 2ê°€ì§€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤.

1. **settings.py**
   
    **settings.py**ì— **LOG_FILE = '<íŒŒì¼ëª…>.txt'**ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    
    ```python
    #settings.py
    # ì˜ˆ
    LOG_FILE = 'log.txt'    # ì§ì ‘ ì…ë ¥
    ```
    
    ![1](./images/WEEK4/1.png)
    
   <br>
   
1. **spider ì‹¤í–‰ ëª…ë ¹ì–´**

    spider ì‹¤í–‰ ëª…ë ¹ì–´ì— **-s LOG_FILE=<íŒŒì¼ëª…>.log** ë¥¼ ë§ë¶™ì…ë‹ˆë‹¤.

    ```powershell
    # ì˜ˆ
    scrapy crawl st11_best -s LOG_FILE=st11.log
    scrapy crawl gg -s LOG_FILE=gg.log
    ```

    - LOG_FILE.mp4 -- ë…¸ì…˜ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš” :)

ì´ë ‡ê²Œ í•˜ë©´ ë¡œê·¸ëŠ” ëª¨ë‘ íŒŒì¼ì— ì €ì¥ë˜ê³ , í„°ë¯¸ë„ì—ëŠ” ì‚¬ìš©ìê°€ ì‘ì„±í•œ printë¬¸ë§Œ ì¶œë ¥ë©ë‹ˆë‹¤.

<br>

ë¡œê·¸ì— ëŒ€í•œ ë” ìì„¸í•œ ë‚´ìš©ì€ Scrapy ê³µì‹ ì‚¬ì´íŠ¸ì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¸ê³ í•´ë³´ì„¸ìš”.

- [[Scrapy] Logging](https://docs.scrapy.org/en/latest/topics/logging.html)

<br>

## ** ì‹¤ìŠµ ê³¼ì œ

ì‹¤ìŠµ ê³¼ì œëŠ” 3ì£¼ì°¨ ê³¼ì œì™€ ìœ ì‚¬í•©ë‹ˆë‹¤. **Gë§ˆì¼“ ì‚¬ì´íŠ¸ì˜ ëª¨ë“  ë©”ì¸ ì¹´í…Œê³ ë¦¬, ì„œë¸Œ ì¹´í…Œê³ ë¦¬ì˜ ë² ìŠ¤íŠ¸ ìƒí’ˆ 1~5ìœ„ë¥¼ í¬ë¡¤ë§**í•˜ë©´ ë¼ìš”.

- Gë§ˆì¼“ robots.txt í™•ì¸í•˜ê¸°: [https://www.gmarket.co.kr/robots.txt](https://www.gmarket.co.kr/robots.txt)
- Gë§ˆì¼“ ë² ìŠ¤íŠ¸ ì¹´í…Œê³ ë¦¬ ì£¼ì†Œ: [http://corners.gmarket.co.kr/Bestsellers](http://corners.gmarket.co.kr/Bestsellers)

<br>

- **í¬ë¡¤ë§í•´ì•¼ ë˜ëŠ” ë°ì´í„°(ìˆœì„œ ì§€í‚¬ ê²ƒ)**
    1. ë©”ì¸ ì¹´í…Œê³ ë¦¬ëª…
    2. ì„œë¸Œ ì¹´í…Œê³ ë¦¬ëª…
    3. ìƒí’ˆ ìˆœìœ„
    4. ìƒí’ˆëª…
    5. ê¸°ì¡´ ê°€ê²©
    6. í• ì¸ ê°€ê²©
    7. í• ì¸ìœ¨(new)

<br>

- **ì¡°ê±´**
    1. ê¸°ì¡´ ê°€ê²©ì´ ì—†ì„ ê²½ìš° í• ì¸ ê°€ê²©ê³¼ ê°™ê²Œ í•´ì¤„ ê²ƒ
    2. í• ì¸ìœ¨ì´ ì—†ìœ¼ë©´ '0'ìœ¼ë¡œ ì²˜ë¦¬í•  ê²ƒ
    3. **pipelines.py ì„¤ì •ì„ í†µí•´** ê°€ê²©ì—ì„œ ì‰¼í‘œ(,)ë¥¼ ì—†ì• ê³ , 'ì›'ì€ 'ëƒ¥'ìœ¼ë¡œ ë°”ê¿”ì¤„ ê²ƒ (ì˜ˆ: 200,102ì› > 200102ëƒ¥)
    4. LOG_LEVELì€ ERRORë¡œ ì„¤ì •í•  ê²ƒ

<br>

- **íŒíŠ¸**
    - **Gë§ˆì¼“ì€ 11ë²ˆê°€ì™€ ë‹¬ë¦¬ ì¹´í…Œê³ ë¦¬ ì£¼ì†Œ(url)ë¥¼ ë‹´ê³  ìˆëŠ” íƒœê·¸ê°€ ìˆë‹¤. ì´ íƒœê·¸ì˜ ê²½ë¡œë¥¼ ì ê·¹ í™œìš©í•  ê²ƒ** ğŸ§­

    - settings.pyì— ì¶”ê°€í•´ì•¼ ë˜ëŠ” ì„¤ì • ë¹ íŠ¸ë¦¬ì§€ ë§ ê²ƒ
      
        (ê¼­ ë„£ì–´ì£¼ì„¸ìš” ^^ ì•ˆ ê·¸ëŸ¬ë©´ ì •ì‹  ë‚˜ê°‘ë‹ˆë‹¤. ì–´ë–»ê²Œ ì•„ëƒê³ ìš”? ì €ë„ ì•Œê³  ì‹¶ì§€ ì•Šì•˜ì–´ìš”...)

<br>

- **ì œì¶œí•´ì•¼ ë˜ëŠ” íŒŒì¼(ZIPìœ¼ë¡œ ì••ì¶•)**
    1. í¬ë¡¤ë§ ë°ì´í„°ê°€ ë‹´ê¸´ csv íŒŒì¼
    2. ë¡œê·¸íŒŒì¼
    3. **pipelines.py** íŒŒì¼


<br>

---